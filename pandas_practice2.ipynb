{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fce39d6-7cdf-4915-90d3-510d511fab1b",
   "metadata": {},
   "source": [
    "# Difficult type questions of pandas practice. #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafeb31-56ec-477e-82d1-c7babe63d218",
   "metadata": {},
   "source": [
    "## We use DataFrame from pandas practice kernel that is being extracted into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf91b4c-834a-40e6-94df-5d224bf59a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb08295b-ac90-41a3-bd96-27786a58dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>region</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>order_date</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>doll_id</th>\n",
       "      <th>light_id</th>\n",
       "      <th>cumulative_sales</th>\n",
       "      <th>sales_category</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>sales_rank</th>\n",
       "      <th>rolling_profit_average</th>\n",
       "      <th>z-score</th>\n",
       "      <th>currency</th>\n",
       "      <th>average_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2</td>\n",
       "      <td>Name_8</td>\n",
       "      <td>East</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0.762919</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244462</td>\n",
       "      <td>0.476602</td>\n",
       "      <td>6930.53</td>\n",
       "      <td>Medium</td>\n",
       "      <td>48.884717</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587069</td>\n",
       "      <td>297.0</td>\n",
       "      <td>Above Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_5</td>\n",
       "      <td>Name_18</td>\n",
       "      <td>West</td>\n",
       "      <td>Product_8</td>\n",
       "      <td>Food</td>\n",
       "      <td>0.712614</td>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408930</td>\n",
       "      <td>0.460069</td>\n",
       "      <td>13426.93</td>\n",
       "      <td>Medium</td>\n",
       "      <td>73.418817</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>524.0</td>\n",
       "      <td>Above Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_6</td>\n",
       "      <td>Name_16</td>\n",
       "      <td>North</td>\n",
       "      <td>senthalampoo</td>\n",
       "      <td>Food</td>\n",
       "      <td>0.075173</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390509</td>\n",
       "      <td>0.147329</td>\n",
       "      <td>14422.29</td>\n",
       "      <td>Low</td>\n",
       "      <td>2.716605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.512865</td>\n",
       "      <td>-1.505593</td>\n",
       "      <td>795.0</td>\n",
       "      <td>Below Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_7</td>\n",
       "      <td>Name_15</td>\n",
       "      <td>East</td>\n",
       "      <td>Aran</td>\n",
       "      <td>Food</td>\n",
       "      <td>0.545764</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674689</td>\n",
       "      <td>19478.80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>24.530160</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.391797</td>\n",
       "      <td>-0.073686</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Below Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_8</td>\n",
       "      <td>Name_9</td>\n",
       "      <td>South</td>\n",
       "      <td>rama</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0.177651</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235044</td>\n",
       "      <td>0.500523</td>\n",
       "      <td>21358.54</td>\n",
       "      <td>Low</td>\n",
       "      <td>22.353091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>-1.193772</td>\n",
       "      <td>257.0</td>\n",
       "      <td>Below Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     name region       product  category  total_sales  order_date  \\\n",
       "0  ID_2   Name_8   East          Arun  Clothing     0.762919  2024-08-10   \n",
       "1  ID_5  Name_18   West     Product_8      Food     0.712614  2024-11-26   \n",
       "2  ID_6  Name_16  North  senthalampoo      Food     0.075173  2024-12-02   \n",
       "3  ID_7  Name_15   East          Aran      Food     0.545764  2024-05-06   \n",
       "4  ID_8   Name_9  South          rama  Clothing     0.177651  2024-09-04   \n",
       "\n",
       "   price  quantity        date  ...   doll_id  light_id  cumulative_sales  \\\n",
       "0   42.0  1.000000  2022-01-02  ...  0.244462  0.476602           6930.53   \n",
       "1   28.0  0.268817  2022-01-04  ...  0.408930  0.460069          13426.93   \n",
       "2   42.0  0.172043  2022-01-05  ...  0.390509  0.147329          14422.29   \n",
       "3   64.0  0.118280  2022-01-07  ...  0.000000  0.674689          19478.80   \n",
       "4   60.0  0.215054  2022-01-07  ...  0.235044  0.500523          21358.54   \n",
       "\n",
       "   sales_category profit_margin  sales_rank  rolling_profit_average   z-score  \\\n",
       "0          Medium     48.884717         2.0                     NaN  0.587069   \n",
       "1          Medium     73.418817         4.0                     NaN  0.434000   \n",
       "2             Low      2.716605         5.0                0.512865 -1.505593   \n",
       "3          Medium     24.530160         5.0                0.391797 -0.073686   \n",
       "4             Low     22.353091         3.0                0.146606 -1.193772   \n",
       "\n",
       "   currency  average_indicator  \n",
       "0     297.0      Above Average  \n",
       "1     524.0      Above Average  \n",
       "2     795.0      Below Average  \n",
       "3      65.0      Below Average  \n",
       "4     257.0      Below Average  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'E:\\Study\\Projects\\EDA\\pandas_practice_dataframe_output.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bcd51-37d8-4725-adcc-8ba1bdda12c6",
   "metadata": {},
   "source": [
    "## 1.Write a script to impute missing values in a DataFrame using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba4f2f27-73b5-4039-bdbf-dfdaa1bcfb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   average_indicator    bag_id  board_id   book_id     category  cloth_id  \\\n",
      "0      Above Average  0.670603  0.530714  0.668087     Clothing  0.631579   \n",
      "1      Above Average  0.449100  0.590280  0.880026         Food  0.293912   \n",
      "2      Below Average  0.421383  0.714948  0.699477         Food  0.226997   \n",
      "3      Below Average  0.163749  0.615874  0.656665         Food  0.973223   \n",
      "4      Below Average  0.695031  1.000000  0.650894     Clothing  0.000000   \n",
      "5      Above Average  0.561254  0.030094  0.947255  Accessories  0.024710   \n",
      "6      Above Average  0.466934  0.186578  0.378485    Furniture  0.562580   \n",
      "7      Below Average  0.368001  0.625733  0.632913  Accessories  0.449343   \n",
      "8      Below Average  0.331098  0.199359  0.885357  Electronics  0.330956   \n",
      "9      Below Average  0.844403  0.924956  0.245461         Food  1.000000   \n",
      "10     Above Average  0.215057  0.287680  0.178963    Furniture  0.536992   \n",
      "11     Above Average  0.707816  0.071057  0.699959  Accessories  0.235508   \n",
      "12     Below Average  0.619353  0.655823  0.560594         Food  0.446435   \n",
      "13     Below Average  1.000000  0.556009  0.765156    Furniture  0.488434   \n",
      "14     Below Average  0.277719  0.633271  1.000000  Electronics  0.461373   \n",
      "15     Below Average  0.428876  0.435637  0.371395    Furniture  0.036711   \n",
      "16     Above Average  0.167232  0.242792  0.000000  Electronics  0.711513   \n",
      "17     Above Average  0.681864  0.756995  0.648036  Accessories  0.846697   \n",
      "18     Below Average  0.603259  0.000000  0.884568    Furniture  0.373621   \n",
      "19     Below Average  0.000000  0.132205  0.056652  Electronics  0.298432   \n",
      "20     Above Average  0.254616  0.374804  0.222509     Clothing  0.081597   \n",
      "21     Below Average  0.345193  0.090406  0.134001         Food  0.874943   \n",
      "\n",
      "      col_12    col_13    col_14    col_15  ...    rating  region   revenue  \\\n",
      "0   0.620332  0.752840  0.295983  0.666760  ...  0.458984    East  0.772361   \n",
      "1   0.688797  0.347241  0.211416  0.378013  ...  0.458984    West  0.771160   \n",
      "2   0.489627  0.783649  0.598309  0.294317  ...  0.465625   North  0.045834   \n",
      "3   0.002075  0.370599  0.663848  1.000000  ...  0.796875    East  0.394864   \n",
      "4   0.497925  0.000000  0.913319  0.024229  ...  0.458984   South  0.129665   \n",
      "5   0.307054  0.155207  0.213531  0.328290  ...  0.387500   North  0.676593   \n",
      "6   0.000000  0.671493  1.000000  0.295789  ...  0.458984    East  0.565497   \n",
      "7   0.238589  0.375583  0.219873  0.717068  ...  0.458984    West  0.282607   \n",
      "8   0.470954  0.867053  0.659619  0.660861  ...  0.003125   South  0.000000   \n",
      "9   0.881743  1.000000  0.913319  0.793052  ...  0.312500   North  0.402662   \n",
      "10  0.815353  0.512925  0.856237  0.740920  ...  0.156250   North  0.919175   \n",
      "11  0.767635  0.286083  0.858351  0.750566  ...  0.458984    West  0.945897   \n",
      "12  0.417012  0.649207  0.902748  0.378415  ...  1.000000   South  0.493947   \n",
      "13  0.699170  0.429431  0.306554  0.759469  ...  0.428125    West  0.123754   \n",
      "14  0.591286  0.418787  0.038055  0.341645  ...  0.950000    West  0.514335   \n",
      "15  0.626556  0.696053  0.188161  0.000000  ...  0.890625    East  0.036497   \n",
      "16  1.000000  0.531556  0.484144  0.927020  ...  0.200000   North  0.773127   \n",
      "17  0.695021  0.742144  0.000000  0.568565  ...  0.281250    West  0.577809   \n",
      "18  0.008299  0.898386  0.649049  0.296799  ...  0.000000    East  0.346739   \n",
      "19  0.485477  0.025416  0.564482  0.777216  ...  0.915625    West  0.146751   \n",
      "20  0.929461  0.485362  0.160677  0.540407  ...  0.034375   South  1.000000   \n",
      "21  0.060166  0.304394  0.701903  0.230533  ...  0.521875    East  0.596646   \n",
      "\n",
      "    rolling_profit_average  sales_category  sales_rank     status  table_id  \\\n",
      "0                 0.350423          Medium         2.0    shipped  0.551289   \n",
      "1                 0.350423          Medium         4.0    ordered  0.306818   \n",
      "2                 0.512865             Low         5.0    pending  0.245757   \n",
      "3                 0.391797          Medium         5.0  delivered  1.000000   \n",
      "4                 0.146606             Low         3.0    pending  0.077719   \n",
      "5                 0.379104          Medium         3.0    shipped  0.525763   \n",
      "6                 0.442659          Medium         4.0   returned  0.212270   \n",
      "7                 0.444220             Low         5.0    ordered  0.369609   \n",
      "8                 0.216740             Low         4.0  delivered  0.460473   \n",
      "9                 0.189482          Medium         4.0    ordered  0.351207   \n",
      "10                0.480410            High         1.0    shipped  0.329484   \n",
      "11                0.761281            High         1.0  delivered  0.211565   \n",
      "12                0.646531            High         2.0   returned  0.445944   \n",
      "13                0.376646             Low         7.0    shipped  0.202662   \n",
      "14                0.193407            High         2.0    pending  0.000000   \n",
      "15                0.197442             Low         6.0    shipped  0.581261   \n",
      "16                0.421444            High         2.0    pending  0.412583   \n",
      "17                0.504613            High         3.0    pending  0.529738   \n",
      "18                0.544424          Medium         3.0  delivered  0.774509   \n",
      "19                0.311013             Low         6.0    pending  0.783184   \n",
      "20                0.401982            High         1.0   returned  0.808119   \n",
      "21                0.349507            High         1.0    pending  0.630814   \n",
      "\n",
      "    total_sales   z-score  \n",
      "0      0.762919  0.587069  \n",
      "1      0.712614  0.434000  \n",
      "2      0.075173 -1.505593  \n",
      "3      0.545764 -0.073686  \n",
      "4      0.177651 -1.193772  \n",
      "5      0.643033  0.222282  \n",
      "6      0.598247  0.086008  \n",
      "7      0.422338 -0.449243  \n",
      "8      0.000000 -1.734326  \n",
      "9      0.491874 -0.237663  \n",
      "10     1.000000  1.308454  \n",
      "11     0.983861  1.259345  \n",
      "12     0.787603  0.662177  \n",
      "13     0.159551 -1.248846  \n",
      "14     0.812603  0.738247  \n",
      "15     0.076034 -1.502973  \n",
      "16     0.782795  0.647548  \n",
      "17     0.805274  0.715946  \n",
      "18     0.602765  0.099755  \n",
      "19     0.167457 -1.224793  \n",
      "20     0.970963  1.220099  \n",
      "21     0.961060  1.189967  \n",
      "\n",
      "[22 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Seperate the datetime columns\n",
    "date_time_features = df.select_dtypes(include=['datetime64']).columns\n",
    "numerical_features = df.select_dtypes(include=['number']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Exclude datetime columns before imputation\n",
    "df_numeric = df[numerical_features.union(categorical_features)] # keep only numeric and categorical variables\n",
    "\n",
    "# Apply KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_numeric), columns=df_numeric.columns)\n",
    "\n",
    "# Decode categorical variables\n",
    "for colu in label_encoders:\n",
    "    df_imputed[colu] = df_imputed[colu].round().astype(int)\n",
    "    df_imputed[colu] = label_encoders[colu].inverse_transform(df_imputed[colu])\n",
    "\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c91135-2770-481f-867f-3535d44b62ca",
   "metadata": {},
   "source": [
    "## 2.Create a DataFrame with hierarchical indexes based on region and category and calculate group statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad2d967-ed2e-4718-bb90-e56099d4f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">id</th>\n",
       "      <th colspan=\"3\" halign=\"left\">name</th>\n",
       "      <th colspan=\"3\" halign=\"left\">product</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_rank</th>\n",
       "      <th colspan=\"3\" halign=\"left\">z-score</th>\n",
       "      <th colspan=\"3\" halign=\"left\">currency</th>\n",
       "      <th colspan=\"3\" halign=\"left\">average_indicator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762919</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.587069</td>\n",
       "      <td>0.587069</td>\n",
       "      <td>0.587069</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>15</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.506824</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.116281</td>\n",
       "      <td>0.558141</td>\n",
       "      <td>0.558141</td>\n",
       "      <td>846.0</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>423.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.277046</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.317210</td>\n",
       "      <td>-0.439070</td>\n",
       "      <td>0.086008</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>527.666667</td>\n",
       "      <td>515.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.643033</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>486.0</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.782795</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.647548</td>\n",
       "      <td>0.647548</td>\n",
       "      <td>0.647548</td>\n",
       "      <td>159.0</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>13</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>26</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.567046</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.743256</td>\n",
       "      <td>-0.871628</td>\n",
       "      <td>-0.871628</td>\n",
       "      <td>916.0</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>458.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308454</td>\n",
       "      <td>1.308454</td>\n",
       "      <td>1.308454</td>\n",
       "      <td>353.0</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>18</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.148614</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>443.0</td>\n",
       "      <td>221.500000</td>\n",
       "      <td>221.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.734326</td>\n",
       "      <td>-1.734326</td>\n",
       "      <td>-1.734326</td>\n",
       "      <td>172.0</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.787603</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.662177</td>\n",
       "      <td>0.662177</td>\n",
       "      <td>0.662177</td>\n",
       "      <td>154.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.211473</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.526048</td>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>384.666667</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>19</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.980060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.486546</td>\n",
       "      <td>-0.243273</td>\n",
       "      <td>-0.243273</td>\n",
       "      <td>867.0</td>\n",
       "      <td>433.500000</td>\n",
       "      <td>433.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.712614</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>524.0</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.159551</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.248846</td>\n",
       "      <td>-1.248846</td>\n",
       "      <td>-1.248846</td>\n",
       "      <td>384.0</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                   name                   product  \\\n",
       "                sum       mean median  sum       mean median     sum   \n",
       "region category                                                        \n",
       "0      1          6   6.000000    6.0   16  16.000000   16.0       1   \n",
       "       3         35  17.500000   17.5   15   7.500000    7.5      12   \n",
       "       4         23   7.666667   10.0   31  10.333333   10.0      20   \n",
       "1      0         21  21.000000   21.0   14  14.000000   14.0       5   \n",
       "       2         11  11.000000   11.0   13  13.000000   13.0       3   \n",
       "       3         21  10.500000   10.5   13   6.500000    6.5      26   \n",
       "       4          4   4.000000    4.0    6   6.000000    6.0      14   \n",
       "2      1         35  17.500000   17.5   18   9.000000    9.0      18   \n",
       "       2          2   2.000000    2.0   15  15.000000   15.0      13   \n",
       "       3          7   7.000000    7.0    7   7.000000    7.0       4   \n",
       "3      0         18   6.000000    5.0   27   9.000000    8.0      22   \n",
       "       2         23  11.500000   11.5    5   2.500000    2.5      19   \n",
       "       3         17  17.000000   17.0    4   4.000000    4.0       9   \n",
       "       4          8   8.000000    8.0   11  11.000000   11.0       8   \n",
       "\n",
       "                                  total_sales  ... sales_rank   z-score  \\\n",
       "                      mean median         sum  ...     median       sum   \n",
       "region category                                ...                        \n",
       "0      1          1.000000    1.0    0.762919  ...        2.0  0.587069   \n",
       "       3          6.000000    6.0    1.506824  ...        3.0  1.116281   \n",
       "       4          6.666667    8.0    1.277046  ...        4.0 -1.317210   \n",
       "1      0          5.000000    5.0    0.643033  ...        3.0  0.222282   \n",
       "       2          3.000000    3.0    0.782795  ...        2.0  0.647548   \n",
       "       3         13.000000   13.0    0.567046  ...        4.5 -1.743256   \n",
       "       4         14.000000   14.0    1.000000  ...        1.0  1.308454   \n",
       "2      1          9.000000    9.0    1.148614  ...        2.0  0.026327   \n",
       "       2         13.000000   13.0    0.000000  ...        4.0 -1.734326   \n",
       "       3          4.000000    4.0    0.787603  ...        2.0  0.662177   \n",
       "3      0          7.333333    6.0    2.211473  ...        3.0  1.526048   \n",
       "       2          9.500000    9.5    0.980060  ...        4.0 -0.486546   \n",
       "       3          9.000000    9.0    0.712614  ...        4.0  0.434000   \n",
       "       4          8.000000    8.0    0.159551  ...        7.0 -1.248846   \n",
       "\n",
       "                                    currency                     \\\n",
       "                     mean    median      sum        mean median   \n",
       "region category                                                   \n",
       "0      1         0.587069  0.587069    297.0  297.000000  297.0   \n",
       "       3         0.558141  0.558141    846.0  423.000000  423.0   \n",
       "       4        -0.439070  0.086008   1583.0  527.666667  515.0   \n",
       "1      0         0.222282  0.222282    486.0  486.000000  486.0   \n",
       "       2         0.647548  0.647548    159.0  159.000000  159.0   \n",
       "       3        -0.871628 -0.871628    916.0  458.000000  458.0   \n",
       "       4         1.308454  1.308454    353.0  353.000000  353.0   \n",
       "2      1         0.013163  0.013163    443.0  221.500000  221.5   \n",
       "       2        -1.734326 -1.734326    172.0  172.000000  172.0   \n",
       "       3         0.662177  0.662177    154.0  154.000000  154.0   \n",
       "3      0         0.508683  0.715946   1154.0  384.666667  347.0   \n",
       "       2        -0.243273 -0.243273    867.0  433.500000  433.5   \n",
       "       3         0.434000  0.434000    524.0  524.000000  524.0   \n",
       "       4        -1.248846 -1.248846    384.0  384.000000  384.0   \n",
       "\n",
       "                average_indicator                   \n",
       "                              sum      mean median  \n",
       "region category                                     \n",
       "0      1                        0  0.000000    0.0  \n",
       "       3                        2  1.000000    1.0  \n",
       "       4                        2  0.666667    1.0  \n",
       "1      0                        0  0.000000    0.0  \n",
       "       2                        0  0.000000    0.0  \n",
       "       3                        2  1.000000    1.0  \n",
       "       4                        0  0.000000    0.0  \n",
       "2      1                        1  0.500000    0.5  \n",
       "       2                        1  1.000000    1.0  \n",
       "       3                        1  1.000000    1.0  \n",
       "3      0                        1  0.333333    0.0  \n",
       "       2                        2  1.000000    1.0  \n",
       "       3                        0  0.000000    0.0  \n",
       "       4                        1  1.000000    1.0  \n",
       "\n",
       "[14 rows x 258 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have object and datetime DataType we need to filter it before we do aggregation\n",
    "dropped_feature = df.drop(columns=['order_date', 'col_62', 'sales_category', 'rolling_profit_average'], inplace=True)\n",
    "\n",
    "# We first create hierarchical index based on region and category column.\n",
    "hierarchial_index = df.set_index(['region', 'category'], inplace=True)\n",
    "hierarchial_df = pd.DataFrame(data=df, index=hierarchial_index, columns=df.columns)\n",
    "hierarchial_df.groupby(['region', 'category']).agg(['sum', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d8a55-55e7-4738-b4a9-c50f0a19fb48",
   "metadata": {},
   "source": [
    "## 3.Write a function to detect and handle duplicate rows based on a fuzzy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb045516-f9df-4111-8c4d-2e923ad33195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_duplicates(df):\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"There were {duplicates} duplicates in the entire DataFrame\")\n",
    "    else:\n",
    "        print('There are no duplicates in a dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24940b32-7dac-44e5-8246-b578c931d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicates in a dataframe\n"
     ]
    }
   ],
   "source": [
    "detect_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6bf0dc9-8dc7-4524-a1ba-cb2638070fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID     Salary Department Joining_Date  Active           City\n",
      "0    1   76217.81         IT   2015-01-31   False  San Francisco\n",
      "1    2  116550.00      Sales   2015-02-28   False    Los Angeles\n",
      "2    3  101239.58      Sales   2015-03-31   False         Austin\n",
      "3    4   91906.09    Finance   2015-04-30    True  San Francisco\n",
      "4    5   60921.30      Sales   2015-05-31   False  San Francisco\n",
      "5    6   60919.62      Sales   2015-06-30    True    Los Angeles\n",
      "6    7   54065.85         HR   2015-07-31   False  San Francisco\n",
      "7    8  110632.33    Finance   2015-08-31    True  San Francisco\n",
      "8    9   92078.05  Marketing   2015-09-30   False    Los Angeles\n",
      "9   10   99565.08    Finance   2015-10-31    True    Los Angeles\n",
      "10  11   51440.91  Marketing   2015-11-30    True       New York\n",
      "11  12  117893.69         HR   2015-12-31   False         Austin\n",
      "12  13  108270.98         IT   2016-01-31    True         Austin\n",
      "13  14   64863.74      Sales   2016-02-29   False  San Francisco\n",
      "14  15   62727.75         HR   2016-03-31   False         Austin\n",
      "15  16   62838.32      Sales   2016-04-30   False  San Francisco\n",
      "16  17   71296.96         IT   2016-05-31   False       New York\n",
      "17  18   86732.95         IT   2016-06-30   False    Los Angeles\n",
      "18  19   80236.15         HR   2016-07-31   False    Los Angeles\n",
      "19  20   70386.04         IT   2016-08-31   False    Los Angeles\n",
      "20  21   92829.70  Marketing   2016-09-30   False         Austin\n",
      "21   1   76217.81         IT   2015-01-31   False  San Francisco\n",
      "22  18   86732.95         IT   2016-06-30   False    Los Angeles\n",
      "23  16   62838.32      Sales   2016-04-30   False  San Francisco\n",
      "24   2  116550.00      Sales   2015-02-28   False    Los Angeles\n",
      "25   9   92078.05  Marketing   2015-09-30   False    Los Angeles\n",
      "26   6   60919.62      Sales   2015-06-30    True    Los Angeles\n",
      "27  12  117893.69         HR   2015-12-31   False         Austin\n",
      "28   4   91906.09    Finance   2015-04-30    True  San Francisco\n",
      "29  19   80236.15         HR   2016-07-31   False    Los Angeles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun Kumar\\AppData\\Local\\Temp\\ipykernel_9284\\920072962.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  'Joining_Date': pd.date_range(start='2015-01-01', periods=21, freq='M'),  # Datetime\n"
     ]
    }
   ],
   "source": [
    "# Since we don't have any duplicates in 'df' DataFrame, we create a new with 9 duplicates\n",
    "# Creating a base DataFrame with 21 unique rows\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "values = {\n",
    "    'ID': np.arange(1, 22),  # Unique IDs from 1 to 21\n",
    "    'Salary': np.random.uniform(50000, 120000, 21).round(2),  # Random float salaries\n",
    "    'Department': np.random.choice(['HR', 'IT', 'Finance', 'Sales', 'Marketing'], 21),  # Categorical\n",
    "    'Joining_Date': pd.date_range(start='2015-01-01', periods=21, freq='M'),  # Datetime\n",
    "    'Active': np.random.choice([True, False], 21),  # Boolean\n",
    "    'City': np.random.choice(['New York', 'San Francisco', 'Chicago', 'Los Angeles', 'Austin'], 21)  # String\n",
    "}\n",
    "\n",
    "temp_data = pd.DataFrame(values)\n",
    "\n",
    "# Creating 9 duplicate rows from the existing DataFrame\n",
    "duplicates = temp_data.sample(n=9, random_state=42)  # Select 9 random rows to duplicate\n",
    "\n",
    "# Append duplicate rows to the original DataFrame\n",
    "concat_data = pd.concat([temp_data, duplicates], ignore_index=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(concat_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cee312c-9e83-4876-baf2-3ef051cd6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's start build a function to find the duplicates based on fuzzy match \n",
    "# 'thefuzz' is a library used to detect and handle duplicate rows based on a fuzzy string match\n",
    "# We use 'fuzz' because it contains contains different similarity scoring functions\n",
    "# We use 'process' because it provides utility functions for comparing a string against a list\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# We build a function and pass df, column & threshold\n",
    "# Threshold Setting: Define a similarity threshold (e.g., 90%) to determine duplicates.\n",
    "\n",
    "def detect_fuzzy_duplicates(concat_data, column_name, threshold=90):\n",
    "# Let's copy the dataframe to a variable so that the original dataframe is not being disturbed\n",
    "    data = concat_data.copy()\n",
    "    \n",
    "# Let's initialize few helper variables\n",
    "# Adding a placeholder column\n",
    "    data['duplicate_column'] = -1 # Placeholder for grouping similar records\n",
    "    checked_indices = set() # A set to keep track of rows that have already been matched\n",
    "    group_id = 0 # A counter to assign group numbers to similar entries\n",
    "\n",
    "# Iterates over each row in the specified column\n",
    "    for i, text in enumerate(data[column_name]):\n",
    "# i is the row index, and text is the value from the column\n",
    "        if i in checked_indices:\n",
    "            continue\n",
    "# process.extract() compares text with all other values in the column.\n",
    "# fuzz.token_sort_ratio calculates similarity, ignoring word order.\n",
    "# limit=len(data): Ensures that all rows are compared.\n",
    "        \n",
    "        matches = process.extract(text, data[column_name], scorer=fuzz.token_sort_ratio, limit=len(data))\n",
    "\n",
    "# match_text: The matched string.\n",
    "# score: The similarity percentage (0 to 100).\n",
    "# match_index: The row index of the matched string.\n",
    "        for match_text, score, match_index in matches:\n",
    "            if score >= threshold and match_index not in checked_indices:\n",
    "# Assigns the current group_id to the Duplicate_Group column.\n",
    "                data.at[match_index, 'duplicate_column'] = group_id\n",
    "# Adds the matched index to checked_indices to avoid reprocessing.\n",
    "                checked_indices.add(match_index)\n",
    "# After processing a record and its matches, increments the group_id to start a new group for the next distinct set of matches.\n",
    "        group_id += 1\n",
    "# Returns the DataFrame with an additional Duplicate_Group column.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5322bdb-684b-43f2-9af5-fb66604a097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID     Salary Department Joining_Date  Active           City  \\\n",
      "0    1   76217.81         IT   2015-01-31   False  San Francisco   \n",
      "1    2  116550.00      Sales   2015-02-28   False    Los Angeles   \n",
      "2    3  101239.58      Sales   2015-03-31   False         Austin   \n",
      "3    4   91906.09    Finance   2015-04-30    True  San Francisco   \n",
      "4    5   60921.30      Sales   2015-05-31   False  San Francisco   \n",
      "5    6   60919.62      Sales   2015-06-30    True    Los Angeles   \n",
      "6    7   54065.85         HR   2015-07-31   False  San Francisco   \n",
      "7    8  110632.33    Finance   2015-08-31    True  San Francisco   \n",
      "8    9   92078.05  Marketing   2015-09-30   False    Los Angeles   \n",
      "9   10   99565.08    Finance   2015-10-31    True    Los Angeles   \n",
      "10  11   51440.91  Marketing   2015-11-30    True       New York   \n",
      "11  12  117893.69         HR   2015-12-31   False         Austin   \n",
      "12  13  108270.98         IT   2016-01-31    True         Austin   \n",
      "13  14   64863.74      Sales   2016-02-29   False  San Francisco   \n",
      "14  15   62727.75         HR   2016-03-31   False         Austin   \n",
      "15  16   62838.32      Sales   2016-04-30   False  San Francisco   \n",
      "16  17   71296.96         IT   2016-05-31   False       New York   \n",
      "17  18   86732.95         IT   2016-06-30   False    Los Angeles   \n",
      "18  19   80236.15         HR   2016-07-31   False    Los Angeles   \n",
      "19  20   70386.04         IT   2016-08-31   False    Los Angeles   \n",
      "20  21   92829.70  Marketing   2016-09-30   False         Austin   \n",
      "21   1   76217.81         IT   2015-01-31   False  San Francisco   \n",
      "22  18   86732.95         IT   2016-06-30   False    Los Angeles   \n",
      "23  16   62838.32      Sales   2016-04-30   False  San Francisco   \n",
      "24   2  116550.00      Sales   2015-02-28   False    Los Angeles   \n",
      "25   9   92078.05  Marketing   2015-09-30   False    Los Angeles   \n",
      "26   6   60919.62      Sales   2015-06-30    True    Los Angeles   \n",
      "27  12  117893.69         HR   2015-12-31   False         Austin   \n",
      "28   4   91906.09    Finance   2015-04-30    True  San Francisco   \n",
      "29  19   80236.15         HR   2016-07-31   False    Los Angeles   \n",
      "\n",
      "    duplicate_column  \n",
      "0                  0  \n",
      "1                  1  \n",
      "2                  2  \n",
      "3                  0  \n",
      "4                  0  \n",
      "5                  1  \n",
      "6                  0  \n",
      "7                  0  \n",
      "8                  1  \n",
      "9                  1  \n",
      "10                 3  \n",
      "11                 2  \n",
      "12                 2  \n",
      "13                 0  \n",
      "14                 2  \n",
      "15                 0  \n",
      "16                 3  \n",
      "17                 1  \n",
      "18                 1  \n",
      "19                 1  \n",
      "20                 2  \n",
      "21                 0  \n",
      "22                 1  \n",
      "23                 0  \n",
      "24                 1  \n",
      "25                 1  \n",
      "26                 1  \n",
      "27                 2  \n",
      "28                 0  \n",
      "29                 1  \n"
     ]
    }
   ],
   "source": [
    "fuzzy_duplicates = detect_fuzzy_duplicates(concat_data, 'City')\n",
    "print(fuzzy_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe5e85-d088-4296-b8d3-75a79f187136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
